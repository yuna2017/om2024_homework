# **运维部期末作业**

------

## 写在正式内容之前

上学期的HPCG作业前边也写了一堆碎碎念，不得不缺少的环节说是

还是喜欢捣鼓电脑硬件的，家里边第一台电脑的CPU是老古董I5-4460，后来死缠烂打说服老爸去镇上的电脑店先是加了一张GT 1030，然后发现还是太垃圾了这卡，然后去换了1060。直到购买笔记本之前，那台电脑都是我的主力机，现在到是也没出啥问题，放在家里我爹看电视剧用

上大学前说一定要组台ITX带到大学宿舍，经常进入幻想时间组一堆配置单😋后来买了台笔记本，啊，然后燕大宿舍限电又太离谱，组ITX的幻想只好作罢，不过中途经常帮朋友组电脑，也算是积累了一些经验。等以后挣了大米一定要自己组电脑

但是服务器方面真是接触的较少，这次作业是一个很好的学习机会，配置啥的大多也都是抓的别人的现成方案，B站上还有不少现成的方案，好多硬件都相应着涨价了，坏

------

### 摘要

本文围绕2000元预算下的本地大模型部署需求，设计了一套基于二手服务器硬件的低成本解决方案。通过选用浪潮5212M5双路服务器平台、Intel Xeon 8259CL处理器集群与192GB(存疑) ECC内存的硬件组合，结合LM Studio框架与RAG（检索增强生成）技术，实现了Deepseek R1-671b量化模型在CPU+内存架构上的本地部署。重点探讨了双路CPU并行运算的性能瓶颈、内存带宽利用率优化策略以及基于AnythingLLM的私有知识库构建方案，最终达到1.5-1.8 token/s的推理速度。实验表明该方案在有限预算下具备可行性，但需在计算效率与硬件成本间取得平衡，为入门级本地大模型部署提供了可复现的参考案例

------

### 关键词

------

本地部署 | 大语言模型 | Deepseek R1 | 双路CPU架构 | 内存 | RAG技术 | MCP服务 |量化模型 | 性能瓶颈

### 引入

------

我在问了deepseek他自己后他回答我“若坚持本地部署，做好“玩具级实验”的心理预期，建议额外预留500元应急维修预算”

禁用美国对中国禁运或限制出售的硬件，嗯这还好其实，2000块也不指望用什么最新的至强处理器和NVIDIA的计算卡，应该可以堆CPU和内存让大模型跑在CPU和内存上，还得量化跑，就是个玩具其实，为数不多的优点应该是私密性和安全性，2000块部署全量Deepseek R1最好的办法应该是直接去买token（

### 硬件物料清单

------



| 组件   | 型号/规格                                         | 价格       | 淘宝链接                                                     |
| ------ | ------------------------------------------------- | ---------- | ------------------------------------------------------------ |
| 服务器 | 浪潮5212M5（带800W电源）                          | 950-1000￥ | [浪潮SA5212M4 5212M5服务器2U3.5寸12盘位虚拟云计算渲染x99主机-淘宝网](https://item.taobao.com/item.htm?abbucket=11&detail_redpacket_pop=true&id=816632339754&mi_id=70_YmlLR4tpRZKt17D5D1TCrWXd7JzRA8xVY_e4JmBo2Wi6bLwc1x0mBHs_6zKMB3CaUIWNVyOCqff948jEaAGjpeEa-QSNruRySxpvx6co&ns=1&priceTId=214784b917478157612333212e1c53&query=狼潮英信SA5212M5&skuId=5726737118464&spm=a21n57.1.hoverItem.13&utparam={"aplus_abtest"%3A"7c84c2412931b255c733a8848b01751a"}&xxc=taobaoSearch) |
| CPU    | INTEL XEON 8259CL *2                              | 480￥      | [英特尔至强铂金8255C 8259CL 8270CL 8272CL 8273CL 8275CL CPU-淘宝网](https://item.taobao.com/item.htm?abbucket=11&detail_redpacket_pop=true&id=903632053113&mi_id=6BpUOq6Lo8WVAZO5YCpX8yoCbbjbPrUHwK-PKuDJ5ljDzGUTD1mFT2JoxKFu0QaqfR9yD4I_vx1nJicy-FFITkIQYrXVIkC24KI1eJ8taQ4&ns=1&priceTId=undefined&query=至强8295CL&skuId=5929608683267&spm=a21n57.1.hoverItem.2&utparam={"aplus_abtest"%3A"25fceeb2ec3685ae94bb8c2b11672d4e"}&xxc=taobaoSearch) |
| 内存   | SK海力士16G ERCC *12                              | 1056￥     | [三星16G 32G DDR4 ECC REG PC4-2133P 2400T 2666V服务器内存X99-淘宝网](https://item.taobao.com/item.htm?id=567468034444&skuId=5117877308653&spm=a1z10.5-c-s.w4002-22887490653.14.199a7d1cuc0SmI) |
| 存储   | 随便一120G SSD & 硅脂&刷机需要的各种小玩意 等配件 | ~80￥      | -                                                            |

### 技术规格表

------



| 组件     | 特性                                                         |
| -------- | ------------------------------------------------------------ |
| 服务器   | 浪潮5212M5 最高支持两个志强处理器，最高支持12个内存通道24根内存，这玩意儿要刷机解锁高功率，但是还好网上有菩萨分享刷机包刷机板和后续驱动等乱七八糟的东西 |
| CPU      | INTEL XEON 8259CL *2 24核48线程 最高睿频3.5Ghz，TDP210W 单核性能巨垃圾，但力大砖飞。这款U有Avx512指令集，我记得这个在新酷睿上见不到了。 |
| 内存     | SK海力士ERCC内存 2R*4 16G* 12条共192G 1056￥，在网上大量涌现CPU+大内存跑大模型后商家都趁着涨价，坏，最超预算的一集，其实应该可以砍一半然后上傲腾的，但傲腾这玩意儿让英特尔作没了，生不逢时 |
| 性能预期 | 如果这套系统真能组起来的话，按照参考中别人测试的数据，性能应该在1.5~1.8token/s之间，玩具 |

### 软件架构 

------

使用LM studio配置大模型，本地知识库RAG的搭建使用Anything LLM，但是这套服务器目前有个问题，查询后发现在双路CPU平台上应该是个普遍问题，实际速率比理论速率偏低，内存带宽像是只用了一半，那如果十二通道比六通道没有什么性能提升的话，内存上可以再省下不少钱。而且双CPU似乎不会带来两倍性能，存在瓶颈，双路的跨度大，内存延迟也会变大，神秘

同样神秘AI给的核心配置：

service:
  protocol_mode: stdio              # 本地部署采用标准输入输出模式
  numa_affinity: [0,1]             # 绑定双路CPU的NUMA节点
  memory_policy: interleave        # 内存交错访问优化带宽利用率:cite[10]

model:
  context_sources:
    - type: rag                    # 本地知识库接口
      path: /mnt/anythingllm_db
      auth: token://${API_KEY}
    - type: hardware_monitor       # 硬件状态接口
      metrics: [mem_bandwidth, cpu_temp]

security:
  sandbox_level: 3                 # 启用操作审批流程
  allowed_actions: [file_read, db_query]  # 禁用硬件控制类操作

performance:
  batch_size: 16                   # 适配192GB内存容量
  thread_pool: 32                  # 48线程的70%分配
  cache_strategy: lru@4GB          # 高频数据缓存

### 参考与引用

------

[DeepSeek | 深度求索](https://www.deepseek.com/)

[2000元玩转Deepseek 671b？千元级Deepseek浪潮服务器方案_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1YEPvepEvf/?spm_id_from=333.1387.favlist.content.click&vd_source=e84e6e16771417d9f6ee707b73dfba61)

[【全球首发】不到2000元价格成功快速运行deepseek r1 -671b完整版 q4 q6 fp8量化，并开源配置单与配置方法，可自行购买复现！_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1SPwdevEKP/?spm_id_from=333.1387.favlist.content.click&vd_source=e84e6e16771417d9f6ee707b73dfba61)

[双路E5部署deepseek 671b 最终优化效果_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1YWNVeYEin/?vd_source=e84e6e16771417d9f6ee707b73dfba61)

[实战指南：本地部署大模型与基于RAG构建私有知识库，一步到位！_lm studio rag-CSDN博客](https://blog.csdn.net/2401_85373691/article/details/141470698)

[GitHub - AFAP/ai-learn](https://github.com/AFAP/ai-learn/tree/main)

[使用 DeepSeek-R1 与 AnythingLLM 搭建本地知识库_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1ioFyekEWj/?spm_id_from=333.337.search-card.all.click&vd_source=e84e6e16771417d9f6ee707b73dfba61)

[双路EPYC CPU搭建：避免瓶颈 | LLM Info](https://llminfo.tech/posts/1iyn408/)

[10分钟讲清楚 Prompt, Agent, MCP 是什么_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1aeLqzUE6L/?spm_id_from=333.337.search-card.all.click&vd_source=e84e6e16771417d9f6ee707b73dfba61)

[火遍全网的MCP是什么？怎么用？如何自己开发一个MCP服务？一个视频带你入门！_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV13R5EzbE6E/?spm_id_from=333.337.search-card.all.click&vd_source=e84e6e16771417d9f6ee707b73dfba61)

### 鸣谢与感悟

------

感谢Deepseek，B站、Github和CSDN等互联网上的赛博活菩萨

感谢我的一位朋友，高中同学，同是运维部的部员，他为我提供了作为朋友可以提供的所有东西

感谢我的一位舍友，我的下铺，一位开发部的部员，他为我解答了若干问题

感谢燕山大学网络信息协会
